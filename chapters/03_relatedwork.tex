\section{Related Work}
\label{cha:relatedwork}
The following section introduces related research that has informed and inspired the development of this thesis. It reviews selected works addressing key themes such as workflow monitoring, performance modeling, and scheduling in distributed environments. Much prior research has focused on co-scheduling in high-performance computing (HPC) at the operating system level, on contention management between batch workloads and long-running latency-critical services in cloud data centers, or on multi-objective optimization and metaheuristic approaches for job placement. In contrast, this thesis takes a novel perspective by combining machine learningbased scheduling with online consolidation techniques, explicitly targeting scientific workflows in HPC cluster environments. By embedding this adaptive scheduling logic within a simulation framework that captures resource contention and task-level dynamics, the work extends beyond existing literature and, to the best of our knowledge, represents the first integrated exploration of learning-driven, contention-aware scheduling for workflow execution in simulated HPC systems.

\subsection{Monitoring of Scientific Workflows}
\label{sec:relatedwork_monitoring_scientific_workflows}
Bader et al. present a conceptual framework for advanced monitoring in scientific workflow environments, emphasizing the heterogeneity of metrics and abstraction layers involved in large-scale workflow execution. Their work identifies four distinct monitoring layers—spanning from infrastructure-level telemetry to workflow-level behavior—and positions these as an architectural blueprint for integrating and correlating performance observations across distributed systems. The authors analyze several state-of-the-art workflow management systems to assess their monitoring capabilities and to highlight existing fragmentation in metric collection and interpretation. Their approach is primarily descriptive and infrastructural, focusing on how to organize and harmonize monitoring responsibilities across system components.
In contrast, the work presented in this thesis goes beyond the architectural structuring of monitoring layers and instead operationalizes monitoring data for performance modeling and scheduling decisions. While Bader et al. focus on multi-layer metric aggregation, the present work uses collected measurements—such as runtime and power consumption under co-location—to infer quantitative models of interference and task affinity. Thus, where their contribution establishes the foundation for integrated observability in workflow systems, this thesis builds upon that idea by applying the monitored data directly to predictive, learning-driven scheduling mechanisms that adapt resource allocation based on empirically derived contention profiles \cite{Bader_2022}.

Witzke et al. address the persistent challenge of connecting low-level monitoring data with high-level workflow semantics in distributed scientific computing environments. Their work focuses on tracing I/O behavior across heterogeneous compute nodes, where workflow tasks may execute concurrently and share resources. By integrating system-level telemetry with metadata extracted from workflow logs and container orchestration frameworks such as Kubernetes, the authors propose a methodology to attribute observed resource consumption—particularly I/O activity—to specific workflow tasks. This enables a task-level analysis of performance bottlenecks and inefficiencies, offering valuable insights for optimization. In contrast to their work, which centers on establishing a traceability chain between metrics and logical workflow components, the approach presented in this thesis operates at a higher abstraction level by using modeled and predicted resource interactions to inform scheduling decisions dynamically. Rather than correlating observed traces post-execution, it leverages learned contention patterns and predictive models to influence online task placement, thus turning monitoring insights into proactive scheduling intelligence \cite{Witzke2024}.

\subsection{Characterization of Scientific Workflow Tasks}
\label{sec:relatedwork_characterization_scientific_workflow_tasks}
% Add a couple more examples here at the end for general HPC characterization
Characterizing scientific workflow applications has been a central topic in understanding performance variability and optimization opportunities in large-scale computing environments. Early foundational work by Juve et al. systematically profiled diverse scientific workflows from domains such as astronomy, bioinformatics, and seismic modeling, revealing that despite differences in scientific goals, workflows often exhibit recurring structural and computational patterns. Their study demonstrated that a few dominant job types typically account for most of the total runtime and I/O activity, and that inefficiencies often arise from repeated data access or imbalanced task configurations. This characterization work established the importance of profiling-based insights as a prerequisite for improving workflow scheduling and system utilization.

Subsequent research extended this line of inquiry toward predictive and analytical modeling. Bader et al. conducted a broad survey of workflow task runtime prediction methods, categorizing models by their statistical or machine learning approach, training mode (offline, online, or pre-execution), and level of infrastructure awareness. Their synthesis demonstrated that accurate task-level performance prediction requires both application features and system state information, including heterogeneity and GPU support. In the context of this thesis, such predictive modeling is regarded as a necessary step toward understanding not just isolated task behavior but also inter-task interference when workflows are executed under shared resource conditions.
A related direction emerged from Zhu et al., who developed power- and performance-aware workflow consolidation models based on kernel canonical correlation analysis. Their work introduced temporal signatures to represent CPU, memory, and I/O behavior as time-series features and correlated them with task runtime and power consumption. While their focus remained on offline analysis and consolidation, this approach inspired the feature representation adopted in this thesis, where resource usage patterns are used to model contention and energy impact during online workflow scheduling.
Complementing these modeling efforts, Brondolin et al. introduced DEEP-Mon, a monitoring framework capable of attributing fine-grained power consumption to containerized workloads with negligible system overhead. This kind of container-level observability provides the instrumentation backbone necessary for empirically characterizing workflow behavior, as it enables associating power and performance traces with specific workflow tasks and execution contexts.
Collectively, these works advanced the field from static profiling toward analytical and predictive characterization of workflow behavior. However, they generally focused on offline measurement, individual task modeling, or coarse-grained consolidation in data center contexts.

\subsection{Task Co-location in Scientific Workflows}
\label{sec:relatedwork_task_colocation_scientific_workflows}
% Mention a couple core-level or os-level co-location things here.

Recent research on task co-location has increasingly focused on balancing performance isolation with resource efficiency, particularly in heterogeneous or multi-tenant computing environments. While the motivation—to improve utilization through concurrent execution—is common across contexts, the techniques differ widely depending on whether the target system is a cloud, containerized service infrastructure, or HPC cluster.

Task co-location has become a central strategy for improving resource utilization and energy efficiency in large-scale distributed systems. Early work by Zhu et al. introduced pSciMapper, a consolidation framework designed for scientific workflows in virtualized environments. Their approach treated consolidation as a hierarchical clustering problem, using kernel canonical correlation analysis to model interference between CPU, memory, disk, and network resource profiles. By correlating resource requirements with task runtime and power consumption, pSciMapper achieved significant power savings with minimal slowdown. However, it operated primarily in an offline mode—optimizing workflow placement decisions before execution—and focused on static virtualized environments rather than dynamic HPC workflows.

More recent research has expanded co-location techniques toward data- and container-level optimization. WOW (Workflow-Aware Data Movement and Task Scheduling) by Lehmann et al. proposed a coupled scheduling mechanism that simultaneously steers data movement and task placement to minimize I/O latency and network congestion during workflow execution. Implemented in Nextflow and deployed on Kubernetes, WOW demonstrated how co-location of data and tasks can drastically improve makespan for dynamic scientific workflows. This approach, however, primarily addresses data movement and distributed file system bottlenecks, rather than the interplay of compute, memory, and I/O contention among co-located workflow tasks.

Complementary to WOW, CoLoc by Renner et al. explored distributed data and container co-location in analytic frameworks such as Spark and Flink. By pre-aligning file placement and container scheduling on Hadoop YARN and HDFS, CoLoc improved data locality and reduced network overhead, resulting in execution time reductions of up to 35\%. This work demonstrated the benefits of cross-layer scheduling coordination but focused on recurring, data-intensive jobs rather than the complex, dependency-driven task graphs typical of scientific workflows.

In cloud and service-oriented systems, studies such as OLPart (Chen et al., 2023) and the Interference-Aware Container Orchestration framework (Li et al., 2023) address the challenge of resource partitioning under performance interference. OLPart employs online learning via contextual multi-armed bandits to dynamically partition CPU and memory resources between latency-critical and best-effort jobs, using performance counters to infer sensitivity to contention. Its strength lies in operating without prior workload knowledge, adapting to runtime behavior. Similarly, Li et al. propose a machine learningdriven orchestration approach that introduces scheduling latency as a more accurate interference metric for mixed workloads. Their system predicts host-level interference and adjusts resource allocation in real time to preserve QoS while maximizing utilization. Both works demonstrate how adaptive learning mechanisms can manage contention in containerized or service-oriented environments but are inherently focused on online services rather than scientific workflows with inter-task dependencies.

In the HPC domain, co-location has traditionally been explored through hardware-level modeling and scheduling heuristics. Zacarias et al. present an intelligent resource manager that predicts performance degradation between co-located HPC workloads using performance monitoring counters (PMCs) as model features. The scheduler then selects application mixes that minimize degradation while improving node utilization. This approach achieves measurable improvements over conventional batch scheduling, but it remains focused on pairwise job co-location at the job-manager level and lacks integration with workflow-level task orchestration. Complementary to this, Álvarez et al. introduce nOS-V, a system-wide scheduler enabling fine-grained co-execution of HPC applications at the task level. By dynamically managing shared node resources and bypassing traditional oversubscription mechanisms, nOS-V demonstrates notable gains in throughput and resource efficiency, though it does not incorporate predictive or learning-based adaptation.

A broad body of research has addressed the challenge of performance interference in multi-tenant and consolidated environments, where multiple tasks, processes, or virtual machines share physical resources. Much of this work stems from efforts to optimize system throughput, energy efficiency, and fairness in cloud and HPC contexts, yet the focus typically lies at the level of system services or job managers rather than workflow-specific task scheduling.

Early work by Dwyer et al. pioneered the use of machine learning for online interference estimation on multi-core processors. Their model predicts performance degradation in real time without instrumenting workloads, helping operators in data centers and HPC clusters make informed consolidation decisions. This approach was notable for applying learning-based methods to shared-resource contention but focused primarily on thread- and process-level interference rather than workflow-level orchestration. Complementary to this, Breitbart et al. analyzed co-scheduling of memory-bound and compute-bound applications in supercomputing environments. Their AutoPin+ tool automatically determines suitable combinations of applications to maximize throughput and energy efficiency, demonstrating up to 28\% runtime reduction. However, their strategy remains reactive and application-type specific, without predictive or adaptive capabilities.
Further refinement came from the work of Alves and Drummond, who developed a multivariate model for predicting cross-application interference in virtualized HPC environments. By considering simultaneous access patterns to shared caches, DRAM, and network interfaces, they achieved high accuracy in predicting interference effects across workloads. This work, along with their later Interference-aware Virtual Machine Placement Problem (IVMPP) formulation, demonstrated that combining interference modeling with optimization can effectively reduce degradation while minimizing physical machine usage. Nonetheless, these methods were still anchored in offline modeling and VM placement optimization rather than dynamic or online scheduling.
In data center research, adaptive resource management has evolved toward online learning and multi-objective optimization. The Orchid framework (Chen et al.) and OLPart system introduced contextual multi-armed bandit algorithms for real-time resource partitioning among co-located jobs. These approaches enable systems to autonomously explore and learn optimal resource splits between latency-critical and best-effort workloads, achieving improved throughput and fairness without prior workload knowledge. Similar efforts, such as ScalCCon by Li et al., addressed scalability challenges in correlation-aware VM consolidation through hierarchical clustering, improving both consolidation speed and performance predictability for large-scale infrastructures.
Finally, Sampaio and Barbosa proposed an interference- and power-aware scheduling mechanism incorporating a slowdown estimator that predicts task completion under noisy runtime conditions. Their simulations based on Google Cloud traces demonstrate effective SLA compliance with energy cost reductions, bridging the gap between consolidation efficiency and QoS guarantees.

\subsection{Energy Awareness in Scientific Workflow Execution}
\label{sec:relatedwork_energy_awareness_scientific_workflow_execution}
Related Work: Energy Awareness

Energy measurement at fine granularity has been a recurring challenge across HPC and cloud environments. Raffin and Trystram dissect software-based CPU energy metering with a critical analysis of RAPL mechanisms and an exploration of eBPF as a low-overhead path for accurate, resilient measurements. Their Rust implementation emphasizes pitfalls in timing and counter handling, providing a blueprint for building correct energy profilers on modern x86 platforms. Complementing measurement, Arjona Aroca et al. conduct a component-level characterization of server energy, showing super-linear CPU power behavior and offering validated models that keep estimation error below 5\% for real analytics workloads, while also identifying efficient operating points for NICs and disks. Warade et al. bring these concerns to containers, empirically breaking down the energy footprint of common Dockerized workloads to motivate energy-aware container development and deployment practices.

A parallel line of work focuses on forecasting and control. Algarni et al. evaluate classical time-series models—AR, ARIMA, and ETS—for predicting per-container power, demonstrating that method choice should be tuned to workload/container characteristics, with ETS frequently achieving the lowest MAPE. At the orchestration level, Kuity and Peddoju propose pHPCe, a containerized HPC framework that couples an online LSTM with rolling updates to predict power/performance and a contention-aware power-cap selection mechanism, yielding double-digit power savings at low overhead. In cloud consolidation, Abdessamia et al. apply Binary Gravitational Search for VM placement in heterogeneous data centers, reporting substantial energy savings over first/Best/Worst-fit and particle-swarm baselines. Kumar et al. similarly address green consolidation with task mapping and sleep-state strategies, arguing for policies that explicitly consider both active and idle energy draw to reduce total consumption in multi-tenant clouds.

Energy-aware scheduling for scientific workflows has been studied from both modeling and algorithmic angles. Silva et al. analyze two production I/O-intensive workflows on power-instrumented platforms and show that power is not linearly tied to CPU load; I/O—and even waiting for I/O—materially impacts energy. They introduce an I/O-aware power model that, when integrated into simulation, improves accuracy by orders of magnitude relative to traditional CPU-only models. Building on the importance of accurate models for policy quality, Coleman et al. evaluate popular energy-aware workflow schedulers under this improved model and find that CPU-linearity assumptions can underestimate power by up to 360\% on I/O-heavy workloads; a simple I/O-balancing scheduler guided by the accurate model produces more attractive energymakespan tradeoffs. From an optimization perspective, Durillo, Nae, and Prodan extend HEFT into MOHEFT, a Pareto-based multi-objective scheduler that captures empirical energy behavior on heterogeneous systems, achieving up to 34.5\% energy reductions with marginal makespan impact. Mohammadzadeh et al. pursue metaheuristics, hybridizing Ant Lion Optimizer with Sineosine and chaos-enhanced exploration in WorkflowSim to jointly minimize makespan, cost, and energy for scientific workflows. Choudhary et al. propose a framework that combines task clustering, partial critical path sub-deadlines, and DVFS on compute nodes to reduce transmission and execution energy across several benchmark workflows. Saadi et al. revisit the interplay between clustering and scheduling choices, showing that vertical clustering paired with MaxMin scheduling tends to save energy by lowering makespan, though sensitivity to workflow structure remains.

Energy awareness often intersects with interference management and QoS. Blagodurov and Fedorova advocate contention-aware HPC scheduling, arguing for cluster schedulers that reason about shared resource bottlenecks (e.g., caches, memory controllers) to avoid pathological slowdowns that also waste energy. Sampaio and Barbosa explicitly tie consolidation, slowdown, and power via a slowdown estimator feeding an interference- and power-aware scheduler; simulations based on cloud traces suggest SLA compliance with ~12\% cost reductions. Finally, several lines of work underscore that accurate performance/energy prediction is a precondition for effective energy-aware orchestration: from measurement robustness (Raffin and Trystram) and component characterization (Arjona Aroca et al.), to container-level prediction (Algarni et al., Warade et al.), to model-informed workflow scheduling (Silva et al., Coleman et al., Durillo et al.). Together, these studies advance the state of practice in measuring, modeling, and optimizing energy across the stack—from microarchitectural counters and container runtimes up to workflow-level schedulers and consolidation controllers.