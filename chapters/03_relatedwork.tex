\section{Related Work}
\label{cha:relatedwork}
This chapter presents and discusses research papers that we found to be important and related to this thesis. Additionally, we mention differences between the related work compared to ours.
Firstly, in section \ref{sec:relatedwork_monitoring} we introduce literature in which detailed approaches for overarching monitoring of HPC-application and specifically scientific workflows are presented.
Afterwards, assessments on resource contention and co-location that served as a motivation and fundament for this work are summarized in \ref{sec:relatedwork_contention}. Lastly, task scheduling, and co-scheduling methods for energy- and performance-awareness during workflow execution are discussed in \ref{sec:relatedwork_scheduling}.
Each work described in this chapter has contributed inspiration and conceptual outlines with influence on the approach developed in this thesis.

\subsection{Monitoring of Scientific Workflows}
\label{sec:relatedwork_monitoring}

We begin with a review on literature in the field of monitoring. The Authors of \cite{7274318}, \cite{9139801} and \cite{9653557}
have their focus on HPC systems and identifying means to quantify power consumption by various components and virtualization technologies.

% HPC, Data Centers, Energy
\cite{7274318} conducted an empirical study to characterize power consumption across data center server components. They designed experiments to stress CPUs, network cards, and disks while measuring their energy usage under varying loads and frequencies. They identified optimal operational points and demonstrated that CPU power usage shows a super-linear relationship to load.
% HPC Energy
Additionally, the study by \cite{9139801} examine how HPC workloads consume power in real production environments by collecting data from two medium-scale clusters to capture job-level energy behavior. The work produced an open dataset and analysis framework intended to inform energy-efficient scheduling and resource management in future HPC systems. Their work helped in generally understanding energy consumption patterns in HPC systems thus bridging the knowledge gap and applying it to scientific workflows.

% HPC virtualization
In \cite{9653557}, the authors examined the use of virtualization technologies in high-performance computing systems. They analyzed operating system-level and application-level virtualization approaches and their effects on performance and resource utilization. The paper discussed existing challenges posed by multi-user environments and customization needs in HPC and outlined directions for future development of virtualization in this context.

Shifting the focus to the use-case of scientific workflows, the works by \cite{Bux2013} and \cite{JUVE2013682} provided comprehensive reviews on workflow execution.

% Scientific Workflows
\cite{Bux2013} specifically reviewed how scientific workflow systems handle parallelization in response to growing data volumes, especially in life sciences. The authors compared theoretical strategies with their practical realizations across existing systems. Their review guided us in understanding the parallel nature of workflow execution suitable for our monitoring and co-location.

% Workflow monitoring
Additionally, the paper by \cite{JUVE2013682} focused on specifically characterizing scientific workflow tasks by choosing six scientific domains using profiling tools that capture I/O, memory, and computational behavior of workflow tasks. They identified dominant job types that consume most of the runtime and detected inefficiencies such as repeated data reads. They introduced new profiling techniques and provided workflow characterizations useful for generating realistic synthetic workflows for simulation and evaluation studies. Their insights on workflow behavior was found valuable for our work.

% Monitoring layers
Papers \cite{Bader_2022} and \cite{Witzke2024} presented monitoring architectures and methods tailored for scientific workflows.
The paper by \cite{Bader_2022} defines a four-layer monitoring architecture for scientific workflow executions. It motivates the need for automatic tracing of performance metrics, traces, and behavior across infrastructure, resource manager, workflow, and task layers. Available metrics available at each layer are explained with a focus on how the layers interact. It evaluates five state-of-the-art scientific workflow management systems to identify what is required to adopt the proposed four-layer approach. In our work, we use the identified layers to structure our monitoring approach while mapping specific monitoring tools instead of solely evaluating workflow management systems.

% Container monitoring
As for our empirical execution of real-world scientific workflows, we chose to use containerized pipelines. This choice imposed the necessity to specifically monitor containers. The authors in \cite{10197087} analyzed the energy footprint of Docker containers under different workloads. They measured energy consumption in common containerized environments to assess performance and cost implications.

% Low-level monitoring with eBPF
In \cite{Witzke2024}, the authors developed methods to link low-level resource usage data with higher-level workflow tasks in distributed scientific workflows. They presented three approaches for detailed I/O monitoring and implemented one using eBPF. They proposed a method to associate monitoring data from system-level traces to workflow tasks, first mapping them to physical tasks and then to logical ones.

% ebpf tools for monitoring and energy measurement
Building on the approach by \cite{Witzke2024} we leverage the system developed by \cite{8425477}. They proposed DEEP-Mon, a monitoring tool that measures power consumption and attributes it to individual threads and application containers. The tool enables power usage analysis at the application level for cloud and HPC environments. They demonstrated that DEEP-Mon introduces negligible overhead on system performance and overcomes limitations of earlier monitoring solutions which made it a suitable choice for our work.

% Rapl 
Accompanying the research by \cite{8425477}, \cite{Raffin2024} analyzed the use of Intel's RAPL interface for energy measurement in CPUs and examined common mistakes in existing tools. The authors revisited RAPL's underlying mechanisms and evaluated its behavior with different processor models. They explored the use of eBPF for interacting with RAPL and implemented a Rust-based solution that improves correctness and timing accuracy.
The doctoral thesis by \cite{khan2018energy} investigated energy consumption in server-based computing systems across HPC, scientific, and cloud environments. The work employed Intel's RAPL to measure, model, and analyze power efficiency at both component and system levels. Multiple modeling strategies were explored, including regression, statistical, and non-linear additive approaches, validated using data center logs and EC2 instances.

\subsection{Implications of Resource Contention and Mitigations}
\label{sec:relatedwork_contention}
% General Performance Impact
The study conducted by \cite{5470399} researched on the performance impact of resource contention in multicore processors using a differential analysis approach. The authors compared MPI process bindings to isolate the effects of shared memory hierarchy resources. They evaluated benchmarks across multiple quad-core architectures. The findings provided insights into how shared hardware resources influence application performance and system efficiency in high-end computing environments.

\cite{10.1145/1958746.1958815}, \cite{Blagodurov_2012}, \cite{7349920}, \cite{10.1007/978-3-031-48803-0_31} and \cite{10.1002/cpe.3187} focused on various aspects of measuring, quantifying, and mitigating resource contention in HPC systems. Even though, their focus was not specifically on scientific workflows, their findings still hold true for data-intensive applications and can be generally summarized as effects occurring in HPC environments.

% contention in hpc
The paper by \cite{10.1145/1958746.1958815} addressed performance bottlenecks in modern HPC clusters arising from contention for shared resources both within and across nodes. The authors noted that current schedulers lack mechanisms to account for such interference. To mitigate this, they introduced a set of metrics designed to model shared resource contention and describe job-level utilization and communication patterns. These metrics rely on data collected from hardware performance counters and interconnect monitoring tools.

Similar to \cite{10.1145/1958746.1958815}, \cite{Blagodurov_2012} presented a virtualized HPC cluster framework designed to recognize and manage contention for shared resources such as caches, memory buses, and controllers. The authors aimed to improve workload performance and stability by introducing contention awareness into cluster operation, addressing a limitation in existing HPC systems.

Paper \cite{7349920} examines how co-scheduling memory-bound and compute-bound applications can enhance performance and energy efficiency on supercomputers. To support this, the authors introduced auto pin+, a tool for monitoring and optimizing co-scheduled workloads. Their experiments showed that coordinated co-scheduling can reduce runtime by up to 28\% and energy consumption by twelve percent relative to dedicated runs. They also proposed an adaptive scheduling strategy that adjusts to the composition of jobs in the queue.

The study from \cite{10.1007/978-3-031-48803-0_31} explored topology-aware process-to-core mappings as a means to improve performance in co-allocated HPC workloads. The authors implemented several core enumeration strategies that enable multiple parallel applications to share compute nodes without explicit application awareness. Their experiments showed that such mappings significantly influence memory bandwidth and overall execution time. By analyzing both individual job durations and overall makespan, the work evaluated topology-aware co-allocation as a practical alternative to exclusive node allocation policies in HPC clusters.

The paper by \cite{10.1002/cpe.3187} investigated job striping as an alternative to the traditional exclusive-node scheduling policy in supercomputers. By allowing pairs of jobs from different users to share nodes, the technique aimed to boost overall throughput and energy efficiency.

\cite{11044815}, \cite{8397647} and \cite{10501918} focus specifically on investigating contention effects on certain hardware resources, as well as containerized environments, which are relevant to our work.

% Cache Contention
In \cite{11044815}, the authors developed Contenders, a method for predicting performance loss caused by cache contention when applications share servers. Their approach profiles each application using custom micro-benchmarks to model cache usage and estimate resulting cache misses and execution times under co-scheduling. Evaluations on various application sets showed that Contenders achieves higher prediction accuracy than existing tools.

% Container contention
The study from the paper \cite{8397647} examined interference among Docker containers running on shared Linux hosts. Through targeted experiments on different resource types, the authors observed that containers contend for shared resources and that part of the interference originates from host operating system overhead. Their findings suggest that workload-aware container placement is essential to maintain stable and predictable performance.

Both \cite{10501918} and \cite{6924435} are concerned with slowdown effect occurring when co-locating workloads in virtualized environments.
By introducing scheduling latency as a new metric to capture interference between online and offline services co-located in containerized cloud environments \cite{10501918} found a more precise performance impact on latency-sensitive online workloads. The authors combined this metric with machine learning models to predict interference and guide scheduling decisions. They further developed a predictive scheduler that allocates CPU and memory resources based on workload characteristics and query load.

% contention energy awareness
The research introduced in \cite{6924435} a mechanism to maintain performance guarantees in virtualized clusters where virtual machines contend for shared resources. A slowdown estimator and a power- and interference-aware scheduler formed the core of the approach. The estimator predicted potential deadline violations from noisy slowdown data, prompting rescheduling when required. Through simulations derived from Google Cloud trace-logs, the method demonstrated effective SLA compliance and achieved roughly twelve percent cost savings.

\cite{Chen_2023_3bbb}, \cite{8748923}, \cite{Melo_Alves_2017} and \cite{6468532} take the concept of predicting resource contention, also referred to as performance degradation further by leveraging predictive frameworks.

% predicting degradation 
% The work by \cite{Chen_2023_3bbb} introduced Orchid, an online learning framework for adaptive and fair resource partitioning among colocated jobs in datacenters. Using a contextual multi-armed bandit model, Orchid dynamically learns optimal partitioning strategies based on runtime conditions without requiring prior job knowledge. The framework balances throughput maximization with fairness, adapting to environmental changes while maintaining low computational overhead. Evaluation results showed that Orchid consistently outperforms existing resource partitioning solutions across multiple performance metrics.

% The paper \cite{8748923} tackled the issue of cross-interference in HPC workloads running on shared cloud infrastructure. To address it, the authors formulated the Interference-aware Virtual Machine Placement Problem, which balances interference reduction with efficient machine utilization. They implemented a solution using an Iterated Local Search approach guided by a mathematical model. Results from tests with both industrial and benchmark applications showed a substantial decrease in interference without requiring additional physical resources.

% In \cite{Melo_Alves_2017}, the authors focused on modeling cross-application interference in HPC cloud environments. They observed that interference stems from concurrent access to multiple shared resources, including last-level cache, memory, and network, rather than from a single factor. To capture this complexity, they proposed a multivariate quantitative model that predicts interference levels based on combined access patterns and resource usage similarity. Experiments with real and benchmark HPC applications validated the model's accuracy, showing prediction errors below ten percent in most cases.

% The research by \cite{6468532} applied machine learning to predict performance degradation caused by resource contention among threads and processes on multicore CPUs. The proposed model estimates slowdown in real time without interfering with application execution and generalizes to unseen workloads. Aimed at improving consolidation decisions in data centers and HPC clusters, the approach identifies when colocating applications becomes detrimental to performance. The study demonstrated that the model enhances performance reliability and contributes to energy savings in HPC workloads.

Lastly, the central approach for contention-avoidance was strongly guided by the following works that applied clustering techniques to identify suitable co-location candidates.

% means to avoid contention - clustering
\cite{7237045} presented ScalCCon1, a correlation-aware VM consolidation approach designed to handle scalability challenges in large data centers. The method applied a two-phase clustering scheme to efficiently group virtual machines while minimizing the computational cost of correlation analysis. Experimental results showed that this approach significantly reduced execution time, physical machine usage, and performance violations compared to existing one-phase clustering and correlation-based methods.

With pSciMapper by \cite{5644899}, a power-aware framework for consolidating scientific workflows in virtualized cloud environments. The approach formulated consolidation as a hierarchical clustering problem using an interference-based distance metric and applied kernel canonical correlation analysis to link resource usage with performance and power consumption. Experiments with real and synthetic workflows showed that pSciMapper can cut power usage by more than half while keeping performance degradation below fifteen percent. The framework also demonstrated low scheduling overhead and strong scalability for large workflow workloads.

\subsection{Energy-Aware Scheduling, Co-Scheduling and Task Mapping in HPC Workflows}
\label{sec:relatedwork_scheduling}

% General
The chapter by \cite{thamsen2025energyawareworkflowexecutionoverview} examined the environmental impact of scientific workflows by estimating the carbon footprint of three real-world applications from different domains. It discussed strategies for reducing energy use and emissions at both task and workflow levels. The proposed techniques included exploiting energy-efficient hardware, optimizing code generation, adjusting processor frequencies, consolidating workloads, and applying energy-aware scheduling to improve overall sustainability in large-scale computational research.

As mentioned in the previous section \ref{sec:relatedwork_contention}, the work by \cite{5644899} achieved significant power savings with minimal slowdown by applying the approach outlined in \cite{thamsen2025energyawareworkflowexecutionoverview}. However, it operated primarily in an offline mode, optimizing workflow placement decisions before execution and focused on static virtualized environments rather than dynamic HPC workflows. Although adapting their concepts of temporal signature computation and application of dissimilarity-based task clustering we extend the approach to an online scheduling context.

More recent research has expanded co-location techniques toward data- and container-level optimization. WOW by \cite{11044799} proposed a coupled scheduling mechanism that simultaneously steers data movement and task placement to minimize I/O latency and network congestion during workflow execution. Implemented in Nextflow and deployed on Kubernetes, WOW demonstrated how co-location of data and tasks can drastically improve makespan for dynamic scientific workflows. This approach, however, primarily addresses data movement and distributed file system bottlenecks, rather than the interplay of compute, memory, and I/O contention among co-located workflow tasks.

Complementary to WOW, CoLoc \cite{7840954} explored distributed data and container co-location in analytic frameworks such as Spark and Flink. By pre-aligning file placement and container scheduling on Hadoop YARN and HDFS, CoLoc improved data locality and reduced network overhead, resulting in execution time reductions of up to 35\%. This work demonstrated the benefits of cross-layer scheduling coordination but focused on recurring, data-intensive jobs rather than the complex, dependency-driven task graphs typical of scientific workflows.

Energy-aware scheduling for scientific workflows has been studied from both modeling and algorithmic angles.
% Task Scheduling in general

% Simulation Algorithms
The work by \cite{8301529} conducted an extensive comparative study of list-scheduling and cluster-scheduling heuristics for makespan minimization in DAG-based parallel programs. By analyzing algorithms across rather than within categories, the study clarified how each approach performs under varying processor constraints.

\cite{10771770} analyzed scheduling algorithms for scientific workflows across various computing environments. Covering studies from 2010 to 2023, it categorized algorithms by optimization goals, techniques, and evaluation criteria. The findings showed that cloud platforms dominate current research while areas such as stream processing, energy efficiency, and hybrid environments remain underexplored.

The survey by \cite{HosseiniShirvani2024} reviewed task scheduling approaches for workflow executions in cloud environments. The authors focused on balancing the objectives of users and providers while maintaining cost efficiency and service quality. Their work introduced a taxonomy that classifies existing algorithms by scheduling strategy, optimization goals, and evaluation metrics. The survey also discussed current challenges and research gaps, outlining directions for improving task scheduling mechanisms in future studies.

Building on the discussion of scheduling strategies in cloud-based workflows, the paper by \cite{9284517} the authors extended the analysis to large-scale scientific workflows operating over big data environments. This work emphasized the trade-off between makespan and monetary cost as central factors in workflow scheduling. The authors proposed a taxonomy of algorithms reflecting these priorities and evaluated key workflow management systems in terms of usability and performance. Their study complemented prior surveys by providing a more focused and comparative examination of leading scheduling approaches and systems.
From an optimization perspective, \cite{Durillo_2014} extend HEFT into MOHEFT, a Pareto-based multi-objective scheduler that captures empirical energy behavior on heterogeneous systems, achieving up to 34.5\% energy reductions with marginal makespan impact.
\cite{Mohammadzadeh_2020} pursue metaheuristics to jointly minimize makespan, cost, and energy for scientific workflows.
\cite{Choudhary_2022} propose a framework that combines task clustering, partial critical path sub-deadlines, and DVFS on compute nodes to reduce transmission and execution energy across several benchmark workflows.
\cite{Saadi_2023} revisit the interplay between clustering and scheduling choices, showing that vertical clustering paired with MaxMin scheduling tends to save energy by lowering makespan, though sensitivity to workflow structure remains.
To specifically target the energy-efficiency during workflow execution, several approaches were proposed for both cloud and traditional cluster environments. \cite{Lee2012}, \cite{Chen_2023_9beb}, \cite{Blagodurov_2015}, \cite{abdessamia2020energy} and \cite{10.1007/978-3-031-23092-9_35} use the performance degradation imposed by close workload co-location as means for optimizing the placement.

% % Energy efficiency in clouds
% The study by \cite{Lee2012} addressed energy inefficiency caused by under-utilized resources in cloud environments. Their work proposed two energy-aware task consolidation heuristics designed to balance high utilization with minimized idle power consumption. The heuristics allocated tasks to resources that achieved minimal energy use without degrading performance. Experimental results showed that the proposed methods effectively reduced total energy consumption while maintaining system efficiency.

% % Energy Aware Co-location
% The study by \cite{Chen_2023_9beb} presented OL-Part, an online learning framework for coordinated resource partitioning in cloud environments where latency-critical and best-effort jobs share servers. The method used contextual multi-armed bandit learning to allocate resources dynamically, guided by runtime performance counters that capture job sensitivities. OL-Part operated without prior job knowledge and introduced mechanisms to manage exploration efficiently with minimal overhead. Experimental results showed that the framework achieved optimal partitioning efficiency and robustness, outperforming existing state-of-the-art approaches.
% \cite{Blagodurov_2015} addressed the challenge of job placement in MapReduce and HPC clusters, where collocation affects both performance and power efficiency. Their study highlighted the trade-off between tight placements, which increase resource contention, and loose placements, which raise network latency and energy use. To resolve this, they introduced a multi-objective optimization approach that balances user-defined goals and identifies job placements achieving an effective compromise between performance and energy consumption.
% \cite{abdessamia2020energy} proposed a virtual machine placement strategy for heterogeneous cloud data centers using the Binary Gravitational Search Algorithm (BGSA). The approach aimed to enhance energy efficiency by reducing power consumption through improved cloud consolidation. BGSA was compared against particle swarm optimization and common heuristic methods such as First-fit, Best-fit, and Worst-fit. Experimental results demonstrated that BGSA achieved greater energy savings and scaled more effectively as the number of virtual machines increased.
% \cite{10.1007/978-3-031-23092-9_35} proposed two energy-aware task consolidation methods aimed at improving resource utilization and reducing both active and idle power consumption in cloud environments. Their approach assigned tasks to resources where energy use was minimized without affecting performance. The study built on the observation that server power consumption scales linearly with processor utilization and incorporated mechanisms to address idle energy waste.

Lastly, the following works include machine learning techniques into their approaches for either predicting performance degradation or optimizing scheduling decisions.

% Prediciton in Workflow Execution
Lotaru, introduced by \cite{BADER2024171}, is a local runtime prediction method for scientific workflows operating on heterogeneous compute clusters. Unlike traditional models requiring historical data, Lotaru predicts task runtimes using microbenchmarks and reduced input profiling during early execution. The method employs Bayesian linear regression to estimate runtimes and quantify prediction uncertainty, supporting adaptive scheduling decisions.
\cite{10496576} explored fine-grained energy prediction for Docker-based applications in cloud data centers. Using time series models they forecasted container-level power consumption over hourly intervals. The analysis compared model performance across multiple containers running diverse workloads and evaluated prediction accuracy. Results showed that ETS achieved the most accurate forecasts for several container types, while ARIMA performed better for others, emphasizing the importance of model selection according to container behavior and workload characteristics.
\cite{10.1007/978-3-030-30143-9_15} introduced a machine learning-based container scheduling and consolidation method for cloud environments. The approach dynamically adjusts the number of active nodes in response to container submission patterns to reduce power consumption. By analyzing historical submission data, it identifies high, medium, and low activity periods and adapts resource usage accordingly. Implemented within Docker Swarmkit, the method showed effective energy savings and adaptability across varying workload scenarios.






